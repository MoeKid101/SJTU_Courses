import jittor as jt
import numpy as np
from jittor.nn import Module

jt.flags.use_cuda = True
CIFAR_ORIG_PATH = 'cifar-10-batches-py'

def genData(fileNames:list, outName:str, doMask:bool=False):
    '''
    The function to generate a file with content (data, label) from the original
    downloaded CIFAR-10 dataset. Here (data, label) are both np.ndarrays with
    shape <data>:(-1, 3, 32, 32) and <label>:(-1).
    '''
    def unpack(filename:str)->dict:
        import pickle
        with open(str.join('/', [CIFAR_ORIG_PATH, filename]), 'rb') as file:
            dict = pickle.load(file, encoding='bytes')
        return dict
    def mask(data:np.ndarray, label:np.ndarray)->tuple[np.ndarray, np.ndarray]:
        label_cond = (label >= 5)
        index_cond = (np.arange(label.shape[0]) % 10 == 0)
        final_cond = np.bitwise_or(label_cond, index_cond)
        return data[final_cond], label[final_cond]
    data_lst, label_lst = list(), list()
    for fileName in fileNames:
        dataDict = unpack(fileName)
        data_lst.append(dataDict[b'data'].reshape((-1, 3, 32, 32)))
        label_lst.append(dataDict[b'labels'])
    dataArr, labelArr = (np.float32(np.concatenate(data_lst, axis=0)) / 256,
                         np.concatenate(label_lst, axis=0))
    if doMask: dataArr, labelArr = mask(dataArr, labelArr)
    jt.save(dataArr, outName)

def augment(std_data:np.ndarray, std_label:np.ndarray):
    return std_data, std_label

def split_image(data_file:str, target_file:str, num_copy:int=2, num_piece:int=4):
    def getSplitRange(size:int=32, model:str='grid'):
        # Returns a list whose elements are four-tuples (start1, start2, end1, end2).
        result = []
        if model == 'grid':
            result.append((0, 0, size//2, size//2))
            result.append((0, size//2, size//2, size))
            result.append((size//2, 0, size, size//2))
            result.append((size//2, size//2, size, size))
            return result
    from numpy import random
    import time
    start_time = time.time()
    data = jt.load(data_file)
    # here data.shape=[-1, 3, 32, 32], we change into [-1, num_piece, 3, 16, 16]
    # the corresponding label should be in shape [-1, num_piece, num_piece], and
    # the contents are the matrix that restores the original sequence.
    dataSpt, labelSpt = (np.zeros((num_copy * data.shape[0], num_piece, 3, 16, 16), dtype=data.dtype),
                         np.zeros((num_copy * data.shape[0], num_piece, num_piece), dtype=np.float32))
    genDataPtr = 0
    imgBuffer = np.zeros((num_piece, 3, 16, 16))
    split_range:list = getSplitRange()
    for idx in range(data.shape[0]):
        local_img = data[idx]
        # split
        for piece_idx in range(num_piece):
            locS1, locS2, locE1, locE2 = split_range[piece_idx]
            imgBuffer[piece_idx] = local_img[:, locS1:locE1, locS2:locE2]
        # generate data
        for copy_idx in range(num_copy):
            # shuffle
            shuffle_idx = np.arange(num_piece)
            random.shuffle(shuffle_idx)
            # load data
            dataSpt[genDataPtr] = imgBuffer[shuffle_idx]
            for piece_idx2 in range(num_piece):
                labelSpt[genDataPtr, piece_idx2, shuffle_idx[piece_idx2]] = 1.0
            genDataPtr += 1
    end_time = time.time()
    print(f'execute time {round(end_time-start_time, 4)}s.')
    jt.save((dataSpt, labelSpt), target_file)

def train_1(model:Module, data_file:str, loss_func, optimizer:jt.optim.Optimizer,
            max_epoch:int, temp_folder:str, from_epoch:int=0, shuffle:bool=True,
            augmentation:bool=False, batch_size:int=128):
    '''
    This function performs a general training process using a given model and <data_file>
    generated by function <genData>. In every epoch it shuffles and augments the data
    according to parameter <shuffle> and <augmentation>, and then split the whole dataset
    into several temprary files. Afterwards, it train the model on every file generated.
    '''
    import time, os
    model.train()
    epoch_losses = list()
    LossSavePath = f'{temp_folder}/loss'
    fin_losses = (jt.load(LossSavePath) if (os.path.exists(LossSavePath) and 
                  from_epoch > 0) else list())
    ModelLoadPath = f'{temp_folder}/model_e{from_epoch}'
    if from_epoch > 0: model.load_state_dict(jt.load(ModelLoadPath))
    dataOrig, labelOrig = jt.load(data_file)
    for epoch in range(from_epoch, max_epoch+1):
        start_time = time.time()
        # augment, copy into GPU and shuffle
        dataArr, labelArr = (augment(dataOrig, labelOrig) if augmentation
                             else (dataOrig, labelOrig))
        dataVar, labelVar = jt.Var(dataArr), jt.Var(labelArr)
        if shuffle:
            shuffle_idx = jt.randperm(dataVar.shape[0])
            dataVar, labelVar = dataVar[shuffle_idx], labelVar[shuffle_idx]
        # generate batches
        batch_num = dataVar.shape[0] // batch_size
        total_num = batch_num * batch_size
        dataVar, labelVar = (dataVar[:total_num].reshape((-1, batch_size, 4, 3, 16, 16)),
                             labelVar[:total_num].reshape((-1, batch_size, 4, 4)))
        for batch_idx in range(batch_num):
            prediction = model(dataVar[batch_idx])
            loss = loss_func(prediction, labelVar[batch_idx])
            optimizer.step(loss)
            epoch_losses.append(loss.item())
            # if batch_idx % 50 == 0: print(batch_idx)
        end_time = time.time()
        # output necessary information
        epoch_loss_avg = jt.mean(jt.Var(epoch_losses)).item()
        epoch_losses.clear()
        fin_losses.append(epoch_loss_avg)
        print(f"Epoch {epoch}. Time {round(end_time-start_time, 4)}s with " + 
              f"average loss {np.round(epoch_loss_avg, 5)}.")
        if epoch % 5 == 0:
            jt.save(model.state_dict(), f'{temp_folder}/model_e{epoch}')
            jt.save(fin_losses, LossSavePath)

def OUTtoLABEL(input:jt.Var, useSinkHorn:bool=False):
    import pygmtools as pgm
    # Expected input.shape=[-1, 4, 4]
    SKresult:jt.Var = pgm.sinkhorn(input) if useSinkHorn else input
    argmax = jt.argmax(SKresult.reshape((-1, 4)), dim=1)[0]
    result = jt.nn.one_hot(argmax)
    return result.reshape((-1, 4, 4))

def val(model:Module, model_file:str, data_file:str, batch_size:int=128):
    model.eval()
    model.load_state_dict(jt.load(model_file))
    dataArr, labelArr = jt.load(data_file)
    batch_num = dataArr.shape[0] // batch_size
    total_num = batch_num * batch_size
    dataVar, labelVar = jt.Var(dataArr), jt.Var(labelArr)
    dataVar, labelVar = (dataVar[:total_num].reshape((-1, batch_size, 4, 3, 16, 16)),
                         labelVar[:total_num].int32().reshape((-1, batch_size, 4, 4)))
    wrong_sum = 0
    for batch_idx in range(batch_num):
        outputs = model(dataVar[batch_idx])
        prediction = OUTtoLABEL(outputs)
        diff = (prediction != labelVar[batch_idx]).reshape((-1, 16))
        wrong_sum += jt.sum(jt.any(diff, dim=1))
    print(wrong_sum/total_num)

def divideDataset(data_path:str, target_path:str, ratio:float=0.7):
    from numpy import random
    dataArr, labelArr = jt.load(data_path)
    shuffle_idx = np.arange(dataArr.shape[0])
    random.shuffle(shuffle_idx)
    dataArr, labelArr = dataArr[shuffle_idx], labelArr[shuffle_idx]
    sepIndex = int(ratio * dataArr.shape[0])
    trainDataArr, trainLabelArr = dataArr[:sepIndex], labelArr[:sepIndex]
    valDataArr, valLabelArr = dataArr[sepIndex:], labelArr[sepIndex:]
    jt.save((trainDataArr, trainLabelArr), f'{target_path}/train')
    jt.save((valDataArr, valLabelArr), f'{target_path}/val')

def std_split(data_file:str, target_file:str, num_piece:int=4):
    def getSplitRange(size:int=32, model:str='grid'):
        # Returns a list whose elements are four-tuples (start1, start2, end1, end2).
        result = []
        if model == 'grid':
            result.append((0, 0, size//2, size//2))
            result.append((0, size//2, size//2, size))
            result.append((size//2, 0, size, size//2))
            result.append((size//2, size//2, size, size))
            return result
    import time
    start_time = time.time()
    data = jt.load(data_file) # data.shape=[-1, 3, 32, 32]
    dataSpt = np.zeros((data.shape[0], num_piece, 3, 16, 16), dtype=data.dtype)
    imgBuffer = np.zeros((num_piece, 3, 16, 16))
    split_range:list = getSplitRange()
    for idx in range(data.shape[0]):
        local_img = data[idx]
        for piece_idx in range(num_piece):
            locS1, locS2, locE1, locE2 = split_range[piece_idx]
            imgBuffer[piece_idx] = local_img[:, locS1:locE1, locS2:locE2]
        dataSpt[idx] = imgBuffer.copy()
    end_time = time.time()
    print(f'execute time {round(end_time-start_time, 4)}s.')
    jt.save(dataSpt, target_file)

def genDataLabel(data:np.ndarray, num_copy:int=2, erase:bool=False):
    from numpy import random
    # expected data.shape=[-1, 4, 3, 16, 16]
    num_pieces = data.shape[1]
    dataGen, labelGen = (np.zeros((num_copy*data.shape[0], num_pieces, 3, 16, 16), dtype=data.dtype),
                         np.zeros((num_copy*data.shape[0], num_pieces, num_pieces,), dtype=np.float32))
    genDataPtr = 0
    for idx in range(data.shape[0]):
        localSpt = data[idx]
        for copy_idx in range(num_copy):
            shuffle_idx = np.arange(localSpt.shape[0])
            random.shuffle(shuffle_idx)
            dataGen[genDataPtr] = localSpt[shuffle_idx]
            if erase:
                erase_idx = np.random.randint(0, 4)
                dataGen[genDataPtr, erase_idx] = np.zeros((3, 16, 16), dtype=dataGen.dtype)
            for piece_idx in range(num_pieces):
                labelGen[genDataPtr, piece_idx, shuffle_idx[piece_idx]] = 1.0
            genDataPtr += 1
    print(dataGen.shape, labelGen.shape)
    return dataGen, labelGen

def genPosLabel(data:np.ndarray, num_copy:int=2):
    ''' Expected original dataset with shape [-1, 3, 32, 32]. '''
    from numpy import random
    num = data.shape[0] * num_copy
    name_map = {'LR':0, 'RL':1, 'UD':2, 'DU':3, 'NO':4}
    oprs = random.randint(0, 6, size=num)
    oprs = np.where(oprs==5, 4, oprs)
    params = random.randint(0, 16, size=num)
    dataGen = np.zeros((num, 2, 3, 16, 16), dtype=data.dtype)
    for idx in range(num):
        img = data[idx % data.shape[0]]
        if oprs[idx] == name_map['LR']:
            dataGen[idx, 0] = img[:, params[idx]:params[idx]+16, 0:16]
            dataGen[idx, 1] = img[:, params[idx]:params[idx]+16, 16:32]
        if oprs[idx] == name_map['RL']:
            dataGen[idx, 1] = img[:, params[idx]:params[idx]+16, 0:16]
            dataGen[idx, 0] = img[:, params[idx]:params[idx]+16, 16:32]
        if oprs[idx] == name_map['UD']:
            dataGen[idx, 0] = img[:, 0:16, params[idx]:params[idx]+16]
            dataGen[idx, 1] = img[:, 16:32, params[idx]:params[idx]+16]
        if oprs[idx] == name_map['DU']:
            dataGen[idx, 1] = img[:, 0:16, params[idx]:params[idx]+16]
            dataGen[idx, 0] = img[:, 16:32, params[idx]:params[idx]+16]
        if oprs[idx] == name_map['NO']:
            locParam = params[idx] // 2
            pair_choice, reverse = locParam // 2, locParam % 2
            locIndex0, locIndex1 = (1,0) if reverse else (0,1)
            locData0, locData1 = ((img[:,0:16,0:16], img[:,16:32,16:32]) if pair_choice
                                  else (img[:,0:16,16:32], img[:,16:32,0:16]))
            dataGen[idx, locIndex0] = locData0
            dataGen[idx, locIndex1] = locData1
    return dataGen, oprs

class HVCrossEntropy(Module):
    def __init__(self, H:bool=True, V:bool=True):
        super().__init__()
        self.stdLoss = jt.nn.CrossEntropyLoss()
        self.h = H
        self.v = V
    def execute(self, output, target):
        ''' Expected output.shape=[-1, 4, 4] and target.shape=[-1, 4, 4] '''
        loss = 0
        if self.h:
            HLabel = (jt.argmax(target, dim=2)[0]).reshape((-1,))
            Houtput = output.reshape((-1, 4))
            loss += self.stdLoss(Houtput, HLabel)
        if self.v:
            VLabel = (jt.argmax(target, dim=1)[0]).reshape((-1,))
            Voutput = jt.transpose(output, (0,2,1)).reshape((-1, 4))
            loss += self.stdLoss(Voutput, VLabel)
        return loss

def train_2(model:Module, data_file:str, loss_func, optimizer:jt.optim.Optimizer,
            max_epoch:int, temp_folder:str, genDataFunc, from_epoch:int=0,
            shuffle:bool=True, batch_size:int=128, num_copy:int=2, testOnTrain:bool=True):
    import time, os
    model.train()
    epoch_losses = list()
    LossSavePath = f'{temp_folder}/loss'
    fin_losses = (jt.load(LossSavePath) if (os.path.exists(LossSavePath) and 
                  from_epoch > 0) else list())
    ModelLoadPath = f'{temp_folder}/model_e{from_epoch}'
    if from_epoch > 0: model.load_state_dict(jt.load(ModelLoadPath))
    dataOrig = jt.load(data_file)
    for epoch in range(from_epoch, max_epoch+1):
        genData_start = time.time()
        ''' generate train data from data file (splitted images). '''
        dataGen, labelGen = genDataFunc(dataOrig, num_copy)
        dataVar, labelVar = jt.Var(dataGen), jt.Var(labelGen)
        if shuffle:
            shuffle_idx = jt.randperm(dataVar.shape[0])
            dataVar, labelVar = dataVar[shuffle_idx], labelVar[shuffle_idx]
        ''' generate batches. '''
        batch_num = dataVar.shape[0] // batch_size
        total_num = batch_num * batch_size
        dataVar, labelVar = (dataVar[:total_num].reshape((-1, batch_size, 4, 3, 16, 16)),
                             labelVar[:total_num].reshape((-1, batch_size, 4, 4)))
        genData_end = time.time()
        print(f'Epoch {epoch}. Generate data cost {round(genData_end-genData_start, 4)}s.')
        Training_start = time.time()
        ''' perform training. '''
        for batch_idx in range(batch_num):
            prediction = model(dataVar[batch_idx])
            loss = loss_func(prediction, labelVar[batch_idx])
            optimizer.step(loss)
            epoch_losses.append(loss.item())
        Training_end = time.time()
        epoch_loss_avg = jt.mean(jt.Var(epoch_losses)).item()
        epoch_losses.clear()
        fin_losses.append(epoch_loss_avg)
        ''' output necessary information. '''
        print(f'Training cost {round(Training_end-Training_start, 4)}s with average ' +
              f'loss {np.round(epoch_loss_avg, 5)}.')
        if epoch % 5 == 0:
            jt.save(model.state_dict(), f'{temp_folder}/model_e{epoch}')
            jt.save(fin_losses, LossSavePath)
        ''' test results. '''
        if not testOnTrain: continue
        model.eval()
        wrong_sum = 0
        for batch_idx in range(batch_num):
            outputs = model(dataVar[batch_idx])
            # print(dataVar[batch_idx].shape, outputs.shape)
            prediction = OUTtoLABEL(outputs, False)
            # print(prediction.shape)
            diff = (prediction != labelVar[batch_idx]).reshape((-1, 16))
            wrong_sum += jt.sum(jt.any(diff, dim=1)).item()
        print(f'Got error rate {round(wrong_sum/total_num,4)} on training set.')
        model.train()

def val_2(model:Module, model_file:str, data_file:str, batch_size:int=128,
          useSinkHorn:bool=False):
    model.eval()
    model.load_state_dict(jt.load(model_file))
    dataArr = jt.load(data_file)
    dataGen, labelGen = genDataLabel(dataArr)
    dataVar, labelVar = jt.Var(dataGen), jt.Var(labelGen)
    batch_num = dataVar.shape[0] // batch_size
    total_num = batch_num * batch_size
    dataVar, labelVar = (dataVar[:total_num].reshape((-1, batch_size, 4, 3, 16, 16)),
                         labelVar[:total_num].reshape((-1, batch_size, 4, 4)))
    wrong_sum = 0
    for batch_idx in range(batch_num):
        outputs = model(dataVar[batch_idx])
        prediction = OUTtoLABEL(outputs, useSinkHorn)
        diff = (prediction != labelVar[batch_idx]).reshape((-1, 16))
        wrong_sum += jt.sum(jt.any(diff, dim=1)).item()
    return wrong_sum / total_num

def plotVal(model:Module, temp_folder:str, train_file:str, test_file:str, out_path:str,
            useSinkHorn:bool=False, from_epoch:int=0, max_epoch:int=90, epoch_itv:int=5):
    
    # train_errs, test_errs = list(), list()
    # epoch_lst = list(range(from_epoch, max_epoch+1, epoch_itv))
    # print(epoch_lst)
    # for epoch in epoch_lst:
    #     model_file = f'{temp_folder}/model_e{epoch}'
    #     train_err = val_2(model, model_file, train_file, useSinkHorn=useSinkHorn)
    #     test_err = val_2(model, model_file, test_file, useSinkHorn=useSinkHorn)
    #     print(train_err, test_err)
    #     train_errs.append(train_err), test_errs.append(test_err)
    # jt.save((epoch_lst, train_errs, test_errs), f'{temp_folder}/err_stat')
    epoch_lst = list(range(0, 71, 5))
    (train_errs, test_errs) = jt.load(f'Permutation/errs_tmp')
    print(test_errs)
    loss_stat = np.array(jt.load(f'{temp_folder}/loss'))
    loss_first5 = 3*loss_stat[:5]
    loss_stat = 3*loss_stat[2:71]
    loss_stat[:5] = loss_first5

    import matplotlib.pyplot as plt
    fig, ax = plt.subplots()
    plt.plot([i for i in range(len(loss_stat))], loss_stat, linewidth=1, c='red', alpha=0.5)
    plt.plot(epoch_lst, train_errs, linewidth=1, c='blue', alpha=0.5)
    plt.plot(epoch_lst, test_errs, linewidth=1, c='green', alpha=0.5)
    plt.scatter([50, 55, 60, 65, 70], [0.212, 0.2119,0.2118,0.2099, 0.2097], c='#FF8C00', marker='+')
    plt.scatter(epoch_lst, train_errs, c='blue', marker='+')
    plt.scatter(epoch_lst, test_errs, c='green', marker='+')
    plt.text(50, 0.19, 'Best Err. 20.97%')
    plt.legend(['Loss', 'Train Error', 'Test Error (no Sinkhorn)', 'Test Error (with Sinkhorn)'])
    plt.ylim(0, 0.35)
    ax.set_aspect(120)
    plt.xlabel('Epoches')
    plt.ylabel('Error Rate.')
    plt.savefig(out_path, dpi=600)
    plt.clf()